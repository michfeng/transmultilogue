{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/pliang279/MultiBench/blob/main/examples/Multibench_Example_Usage_Colab.ipynb","timestamp":1701897604846}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Welcome!\n","\n","This example shows a very basic usage case of MultiBench. In particular, it demonstrates how to use MultiBench with the affective computing dataset MOSI, and how to use it with a very simple fusion model.\n","\n","While this will be simple, it will show off most of the capabilities of MultiBench, and most of the conventions at the heart of the system.\n","\n","To begin, let's clone the repo and setup our interpreter to run commands inside the folder."],"metadata":{"id":"JCnG1gTFJQ-4"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHmaOz8aEZx6","outputId":"ed67849c-59f4-4284-9f8e-da25ac7b2605","executionInfo":{"status":"ok","timestamp":1701898184011,"user_tz":300,"elapsed":3430,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MultiBench'...\n","remote: Enumerating objects: 6937, done.\u001b[K\n","remote: Counting objects: 100% (148/148), done.\u001b[K\n","remote: Compressing objects: 100% (88/88), done.\u001b[K\n","remote: Total 6937 (delta 68), reused 121 (delta 60), pack-reused 6789\u001b[K\n","Receiving objects: 100% (6937/6937), 51.07 MiB | 23.01 MiB/s, done.\n","Resolving deltas: 100% (4254/4254), done.\n","/content/MultiBench\n"]}],"source":["!git clone https://github.com/pliang279/MultiBench.git\n","%cd MultiBench"]},{"cell_type":"markdown","source":["Try to download the data file for MOSI using the below command. If this does not work for you, please download the data file locally, and upload it to the folder \"/content/MultiBench/data/\""],"metadata":{"id":"tUqFe87DIYu9"}},{"cell_type":"code","source":["!mkdir data\n","!pip install gdown\n","# && gdown https://drive.google.com/u/0/uc?id=1szKIqO0t3Be_W91xvf6aYmsVVUa7wDHU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwZS6dfGElh8","outputId":"dbf568bc-aae3-4d7d-abbf-427d0006a3e6","executionInfo":{"status":"ok","timestamp":1701898192048,"user_tz":300,"elapsed":8044,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}]},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=180l4pN6XAv8-OAYQ6OrMheFUMwtqUWbz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqzSQYgoAfkd","executionInfo":{"status":"ok","timestamp":1701898236726,"user_tz":300,"elapsed":44486,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}},"outputId":"170fd93c-6bcd-4f76-a4d9-54a6c71d2904"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=180l4pN6XAv8-OAYQ6OrMheFUMwtqUWbz\n","To: /content/MultiBench/mosei_senti_data.pkl\n","100% 3.73G/3.73G [00:42<00:00, 86.8MB/s]\n"]}]},{"cell_type":"markdown","source":["As Colab famously has bad handling of Conda env files, we'll install the dependencies manually so that it works. Please note that other systems might require installation of a long list of other dependencies."],"metadata":{"id":"nd1ZaCe6JOoA"}},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"Bz_BnnryLQei"}},{"cell_type":"markdown","source":["From here, let's import some of MultiBench and get working:"],"metadata":{"id":"n5S9YcS9J6yk"}},{"cell_type":"code","source":["import torch\n","import sys\n","import os\n","%cd MultiBench"],"metadata":{"id":"mk9zuDMrKMAP","executionInfo":{"status":"ok","timestamp":1701901042083,"user_tz":300,"elapsed":1864,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e91750c-4107-4f53-c300-28d956cc1c32"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/MultiBench\n"]}]},{"cell_type":"markdown","source":["First, we'll import and create the dataloader for the MOSI dataset, which we're working with:"],"metadata":{"id":"U0DyV1CVKpyk"}},{"cell_type":"code","source":["# Import the associated dataloader for affect datasets, which MOSI is a part of.\n","from datasets.affect.get_data import get_dataloader\n","\n","# Create the training, validation, and test-set dataloaders.\n","traindata, validdata, testdata = get_dataloader(\n","    '/content/MultiBench/mosei_senti_data.pkl', robust_test=False, max_pad=True, data_type='mosei', max_seq_len=50)"],"metadata":{"id":"l5enTYMkKtci","executionInfo":{"status":"ok","timestamp":1701901055580,"user_tz":300,"elapsed":13503,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Then, let's define our MultiModal model to test. MultiBench divides models into three separate portions.\n","\n","Firstly, let's define the encoders of the raw modality information, which come from the \"unimodals\" section of MultiBench:"],"metadata":{"id":"riE35efnK5Jr"}},{"cell_type":"code","source":["# Here, we'll import several common modules should you want to mess with this more.\n","from unimodals.common_models import GRU, MLP, Sequential, Identity\n","\n","# As this example is meant to be simple and easy to train, we'll pass in identity\n","# functions for each of the modalities in MOSI:\n","encoders = [Identity().cuda(), Identity().cuda(), Identity().cuda()]"],"metadata":{"id":"n8ZBils-LGgW","executionInfo":{"status":"ok","timestamp":1701901056140,"user_tz":300,"elapsed":596,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Then, let's define the fusion paradigm, which will govern how we take the current modalities, and combine them.\n","\n","For this example, we'll use the ConcatEarly fusion, which just concatenates the inputs along the second dimension."],"metadata":{"id":"XBnSFG3TLZFM"}},{"cell_type":"code","source":["# Import a fusion paradigm, in this case early concatenation.\n","from fusions.common_fusions import ConcatEarly  # noqa\n","\n","# Initialize the fusion module\n","fusion = ConcatEarly().cuda()"],"metadata":{"id":"ifsONTlIMVyb","executionInfo":{"status":"ok","timestamp":1701901056141,"user_tz":300,"elapsed":9,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Lastly, we'll define a 'head' module, which takes the output of the fusion module, and applies transformations to get an output that correponds to our problem - sarcasm detection."],"metadata":{"id":"-mS5anKyMWPD"}},{"cell_type":"code","source":["head = Sequential(GRU(409, 512, dropout=True, has_padding=False,\n","                  batch_first=True, last_only=True), MLP(512, 512, 1)).cuda()"],"metadata":{"id":"6IMQNFDXFJNs","executionInfo":{"status":"ok","timestamp":1701901056322,"user_tz":300,"elapsed":189,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["And with that, we're almost done! Now we just need to put them into one of MultiBench's training loops, and set it running:"],"metadata":{"id":"2nUXcxm2MndX"}},{"cell_type":"code","source":["# Standard supervised learning training loop\n","from training_structures.Supervised_Learning import train, test\n","\n","# For more information regarding parameters for any system, feel free to check out the documentation\n","# at multibench.readthedocs.io!\n","train(encoders, fusion, head, traindata, validdata, 100, task=\"regression\", optimtype=torch.optim.AdamW,\n","      is_packed=False, lr=1e-3, save='mosei_ef_r0.pt', weight_decay=0.01, objective=torch.nn.MSELoss(), track_complexity=False)\n","\n","print(\"Testing:\")\n","model = torch.load('mosei_ef_r0.pt').cuda()\n","test(model, testdata, 'affect', is_packed=False,\n","     criterion=torch.nn.MSELoss(), task=\"regression\", no_robust=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tG3OYAByJ-sX","outputId":"3a46957a-b564-4a56-e75b-5644bc63e7da","executionInfo":{"status":"ok","timestamp":1701902016182,"user_tz":300,"elapsed":428253,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["hi\n","epoch  0\n","Epoch 0 train loss: tensor(1.2816, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.8519967867423948\n","Epoch 0 valid loss: 1.0844184160232544 valid MAE: 0.7779296504850851\n","Saving Best\n","epoch  1\n","Epoch 1 train loss: tensor(1.2374, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.8392663315018708\n","Epoch 1 valid loss: 0.9007430672645569 valid MAE: 0.7271371780669963\n","Saving Best\n","epoch  2\n","Epoch 2 train loss: tensor(1.0101, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.7708404655208999\n","Epoch 2 valid loss: 0.80674147605896 valid MAE: 0.683269563633819\n","Saving Best\n","epoch  3\n","Epoch 3 train loss: tensor(0.8827, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.7158025459229231\n","Epoch 3 valid loss: 0.7546402215957642 valid MAE: 0.6556885658203758\n","Saving Best\n","epoch  4\n","Epoch 4 train loss: tensor(0.8019, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.680856250751451\n","Epoch 4 valid loss: 0.7231867909431458 valid MAE: 0.6444933073861259\n","Saving Best\n","epoch  5\n","Epoch 5 train loss: tensor(0.7462, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.6543813688907849\n","Epoch 5 valid loss: 0.7641794085502625 valid MAE: 0.6583324356424164\n","epoch  6\n","Epoch 6 train loss: tensor(0.7014, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.635122962234398\n","Epoch 6 valid loss: 0.7444703578948975 valid MAE: 0.659908952066897\n","epoch  7\n","Epoch 7 train loss: tensor(0.6765, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.62312873826828\n","Epoch 7 valid loss: 0.7002984285354614 valid MAE: 0.6307619714510511\n","Saving Best\n","epoch  8\n","Epoch 8 train loss: tensor(0.6530, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.6119904868971228\n","Epoch 8 valid loss: 0.6861234903335571 valid MAE: 0.6195048587949854\n","Saving Best\n","epoch  9\n","Epoch 9 train loss: tensor(0.6320, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.6038167728327015\n","Epoch 9 valid loss: 0.7209701538085938 valid MAE: 0.6321946389020414\n","epoch  10\n","Epoch 10 train loss: tensor(0.6102, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5920070360735622\n","Epoch 10 valid loss: 0.6821120381355286 valid MAE: 0.6173633720512502\n","Saving Best\n","epoch  11\n","Epoch 11 train loss: tensor(0.5904, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5813588230388828\n","Epoch 11 valid loss: 0.809636652469635 valid MAE: 0.6781880123458042\n","epoch  12\n","Epoch 12 train loss: tensor(0.5783, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5753929004916\n","Epoch 12 valid loss: 0.7126075029373169 valid MAE: 0.6281065006604355\n","epoch  13\n","Epoch 13 train loss: tensor(0.5607, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.567162018248229\n","Epoch 13 valid loss: 0.7024822235107422 valid MAE: 0.6245931547878578\n","epoch  14\n","Epoch 14 train loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5585620856515506\n","Epoch 14 valid loss: 0.6917599439620972 valid MAE: 0.6213656006158674\n","epoch  15\n","Epoch 15 train loss: tensor(0.5277, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5500316006616742\n","Epoch 15 valid loss: 0.6970678567886353 valid MAE: 0.6222485414820281\n","epoch  16\n","Epoch 16 train loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5381952235653259\n","Epoch 16 valid loss: 0.7174031734466553 valid MAE: 0.6314356818739395\n","epoch  17\n","Epoch 17 train loss: tensor(0.4894, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.52916800930496\n","Epoch 17 valid loss: 0.7575708031654358 valid MAE: 0.6453489462534586\n","epoch  18\n","Epoch 18 train loss: tensor(0.4705, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5202825159068075\n","Epoch 18 valid loss: 0.7253597378730774 valid MAE: 0.6359282813990192\n","epoch  19\n","Epoch 19 train loss: tensor(0.4621, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.513341257574831\n","Epoch 19 valid loss: 0.7454198002815247 valid MAE: 0.6394035889143738\n","epoch  20\n","Epoch 20 train loss: tensor(0.4410, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.5032116260955581\n","Epoch 20 valid loss: 0.7618656754493713 valid MAE: 0.6460604550343838\n","epoch  21\n","Epoch 21 train loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.4920408931178036\n","Epoch 21 valid loss: 0.7424522638320923 valid MAE: 0.6473697582035539\n","epoch  22\n","Epoch 22 train loss: tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.4850558374087388\n","Epoch 22 valid loss: 0.8009975552558899 valid MAE: 0.6622486336305219\n","epoch  23\n","Epoch 23 train loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.478322299340808\n","Epoch 23 valid loss: 0.7946342825889587 valid MAE: 0.6647746511593007\n","epoch  24\n","Epoch 24 train loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.4650896900242708\n","Epoch 24 valid loss: 0.7761147618293762 valid MAE: 0.6635579803869838\n","epoch  25\n","Epoch 25 train loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.45718681185892496\n","Epoch 25 valid loss: 0.7686595916748047 valid MAE: 0.6460843473102812\n","epoch  26\n","Epoch 26 train loss: tensor(0.3484, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.4456341383899134\n","Epoch 26 valid loss: 0.7885912656784058 valid MAE: 0.6589168203010988\n","epoch  27\n","Epoch 27 train loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.43764357999553505\n","Epoch 27 valid loss: 0.7976846098899841 valid MAE: 0.6592567172668846\n","epoch  28\n","Epoch 28 train loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.430294280893851\n","Epoch 28 valid loss: 0.7955682277679443 valid MAE: 0.6629105159059095\n","epoch  29\n","Epoch 29 train loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.41895982540738497\n","Epoch 29 valid loss: 0.8731139898300171 valid MAE: 0.6929346722091756\n","epoch  30\n","Epoch 30 train loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.4085331955372078\n","Epoch 30 valid loss: 0.7961586117744446 valid MAE: 0.6679890003750961\n","epoch  31\n","Epoch 31 train loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.39809635456650305\n","Epoch 31 valid loss: 0.8041583299636841 valid MAE: 0.6620695505624088\n","epoch  32\n","Epoch 32 train loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.39030345485548845\n","Epoch 32 valid loss: 0.7943657040596008 valid MAE: 0.6700496999591733\n","epoch  33\n","Epoch 33 train loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.3825557556772897\n","Epoch 33 valid loss: 0.8868812918663025 valid MAE: 0.7117524644317093\n","epoch  34\n","Epoch 34 train loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.37406475791049726\n","Epoch 34 valid loss: 0.8290384411811829 valid MAE: 0.6825227767504142\n","epoch  35\n","Epoch 35 train loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.36363796459283604\n","Epoch 35 valid loss: 0.8315452933311462 valid MAE: 0.676433983984926\n","epoch  36\n","Epoch 36 train loss: tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.35046292981433474\n","Epoch 36 valid loss: 0.8709470629692078 valid MAE: 0.7004310104790666\n","epoch  37\n","Epoch 37 train loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.3421282491104175\n","Epoch 37 valid loss: 0.8828101754188538 valid MAE: 0.7059375088285195\n","epoch  38\n","Epoch 38 train loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.33177077016746526\n","Epoch 38 valid loss: 0.879290759563446 valid MAE: 0.7031870699617683\n","epoch  39\n","Epoch 39 train loss: tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.32347837687798403\n","Epoch 39 valid loss: 0.8477243781089783 valid MAE: 0.6928369530290764\n","epoch  40\n","Epoch 40 train loss: tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.31185879699663677\n","Epoch 40 valid loss: 0.8827205896377563 valid MAE: 0.7035280818178444\n","epoch  41\n","Epoch 41 train loss: tensor(0.1641, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.30496317999539946\n","Epoch 41 valid loss: 0.8995935320854187 valid MAE: 0.7094565161955809\n","epoch  42\n","Epoch 42 train loss: tensor(0.1491, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.29177534083540607\n","Epoch 42 valid loss: 0.8857066631317139 valid MAE: 0.7054154044161702\n","epoch  43\n","Epoch 43 train loss: tensor(0.1425, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.2845171110195506\n","Epoch 43 valid loss: 0.8956116437911987 valid MAE: 0.7108331441145775\n","epoch  44\n","Epoch 44 train loss: tensor(0.1304, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.27182830847305056\n","Epoch 44 valid loss: 0.8818431496620178 valid MAE: 0.706511870241854\n","epoch  45\n","Epoch 45 train loss: tensor(0.1220, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.26372823063851025\n","Epoch 45 valid loss: 0.8791743516921997 valid MAE: 0.6991088606174009\n","epoch  46\n","Epoch 46 train loss: tensor(0.1125, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.2535097816750027\n","Epoch 46 valid loss: 0.9059180617332458 valid MAE: 0.712585271126354\n","epoch  47\n","Epoch 47 train loss: tensor(0.1022, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.24175782156721687\n","Epoch 47 valid loss: 0.8818811774253845 valid MAE: 0.7084876549828333\n","epoch  48\n","Epoch 48 train loss: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.2362522378545558\n","Epoch 48 valid loss: 0.8991169333457947 valid MAE: 0.7114673782361262\n","epoch  49\n","Epoch 49 train loss: tensor(0.0903, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.2280406650440934\n","Epoch 49 valid loss: 0.9011234641075134 valid MAE: 0.7147907514928368\n","epoch  50\n","Epoch 50 train loss: tensor(0.0846, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.22097074521932827\n","Epoch 50 valid loss: 0.9570200443267822 valid MAE: 0.7396405109265642\n","epoch  51\n","Epoch 51 train loss: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.21372255717861974\n","Epoch 51 valid loss: 0.8739610910415649 valid MAE: 0.7012362828335703\n","epoch  52\n","Epoch 52 train loss: tensor(0.0720, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.20459110898363966\n","Epoch 52 valid loss: 0.8620123267173767 valid MAE: 0.6958429279765578\n","epoch  53\n","Epoch 53 train loss: tensor(0.0707, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.2022614894051745\n","Epoch 53 valid loss: 0.8860024809837341 valid MAE: 0.7107813603530247\n","epoch  54\n","Epoch 54 valid loss: 0.8993743658065796 valid MAE: 0.7123467325546353\n","epoch  55\n","Epoch 55 train loss: tensor(0.0634, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.19175491065114433\n","Epoch 55 valid loss: 0.9271548986434937 valid MAE: 0.720838609006537\n","epoch  56\n","Epoch 56 train loss: tensor(0.0614, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1883654096287203\n","Epoch 56 valid loss: 0.9377866387367249 valid MAE: 0.71877102600286\n","epoch  57\n","Epoch 57 train loss: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.18361862738165274\n","Epoch 57 valid loss: 0.9133073091506958 valid MAE: 0.7110267303477417\n","epoch  58\n","Epoch 58 train loss: tensor(0.0542, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.17684955651136938\n","Epoch 58 valid loss: 0.8692521452903748 valid MAE: 0.6999987819480699\n","epoch  59\n","Epoch 59 train loss: tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1759552275974394\n","Epoch 59 valid loss: 0.8647660613059998 valid MAE: 0.6984870766671728\n","epoch  60\n","Epoch 60 train loss: tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.17173698610590946\n","Epoch 60 valid loss: 0.8945341110229492 valid MAE: 0.712872221220809\n","epoch  61\n","Epoch 61 train loss: tensor(0.0475, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1667459163173479\n","Epoch 61 valid loss: 0.9125013947486877 valid MAE: 0.7185538051288163\n","epoch  62\n","Epoch 62 train loss: tensor(0.0425, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.15749697541841498\n","Epoch 62 valid loss: 0.9050366282463074 valid MAE: 0.7111099180972245\n","epoch  63\n","Epoch 63 train loss: tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.15702067784509255\n","Epoch 63 valid loss: 0.8962224125862122 valid MAE: 0.7089873995051912\n","epoch  64\n","Epoch 64 train loss: tensor(0.0430, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1576947806253594\n","Epoch 64 valid loss: 0.8879582285881042 valid MAE: 0.7043848091695575\n","epoch  65\n","Epoch 65 train loss: tensor(0.0403, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.15361452714545504\n","Epoch 65 valid loss: 0.899116575717926 valid MAE: 0.715167859036011\n","epoch  66\n","Epoch 66 train loss: tensor(0.0375, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1481194950636766\n","Epoch 66 valid loss: 0.8750219345092773 valid MAE: 0.6996959965574416\n","epoch  67\n","Epoch 67 train loss: tensor(0.0415, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.15521064108478685\n","Epoch 67 valid loss: 0.8703319430351257 valid MAE: 0.7011629652447198\n","epoch  68\n","Epoch 68 train loss: tensor(0.0433, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.15738376811252094\n","Epoch 68 valid loss: 0.8727533221244812 valid MAE: 0.7025488482149385\n","epoch  69\n","Epoch 69 train loss: tensor(0.0364, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.14517859030655814\n","Epoch 69 valid loss: 0.8624650239944458 valid MAE: 0.697354867287008\n","epoch  70\n","Epoch 70 train loss: tensor(0.0348, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.14239475045512356\n","Epoch 70 valid loss: 0.8804207444190979 valid MAE: 0.7017654166853383\n","epoch  71\n","Epoch 71 train loss: tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.13776918550477443\n","Epoch 71 valid loss: 0.8648644089698792 valid MAE: 0.7000461499589914\n","epoch  72\n","Epoch 72 train loss: tensor(0.0317, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1360492912097927\n","Epoch 72 valid loss: 0.888454794883728 valid MAE: 0.7112623113798004\n","epoch  73\n","Epoch 73 train loss: tensor(0.0326, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.13684665258507747\n","Epoch 73 valid loss: 0.8562265634536743 valid MAE: 0.6903272360591183\n","epoch  74\n","Epoch 74 train loss: tensor(0.0337, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.13911161639192565\n","Epoch 74 valid loss: 0.8690707683563232 valid MAE: 0.6989251869571693\n","epoch  75\n","Epoch 75 train loss: tensor(0.0358, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.142936055949476\n","Epoch 75 valid loss: 0.8414238691329956 valid MAE: 0.6840830904682286\n","epoch  76\n","Epoch 76 train loss: tensor(0.0286, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.12878118098936484\n","Epoch 76 valid loss: 0.8584351539611816 valid MAE: 0.6935003492791841\n","epoch  77\n","Epoch 77 train loss: tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1342525071795724\n","Epoch 77 valid loss: 0.8422784209251404 valid MAE: 0.6880808609765503\n","epoch  78\n","Epoch 78 train loss: tensor(0.0353, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.14204333386777035\n","Epoch 78 valid loss: 0.8606715798377991 valid MAE: 0.6999642408531161\n","epoch  79\n","Epoch 79 train loss: tensor(0.0312, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1331786991972814\n","Epoch 79 valid loss: 0.8312410116195679 valid MAE: 0.6891793342792554\n","epoch  80\n","Epoch 80 train loss: tensor(0.0291, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.12854820532896613\n","Epoch 80 valid loss: 0.8510153293609619 valid MAE: 0.6961471517099423\n","epoch  81\n","Epoch 81 train loss: tensor(0.0329, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.13624138127459293\n","Epoch 81 valid loss: 0.841564953327179 valid MAE: 0.6879183670805857\n","epoch  82\n","Epoch 82 train loss: tensor(0.0271, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.12478659602126597\n","Epoch 82 valid loss: 0.8666273355484009 valid MAE: 0.6959672092299145\n","epoch  83\n","Epoch 83 train loss: tensor(0.0253, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.12080702034168488\n","Epoch 83 valid loss: 0.8380357027053833 valid MAE: 0.6837339204037935\n","epoch  84\n","Epoch 84 train loss: tensor(0.0238, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.11710821460558017\n","Epoch 84 valid loss: 0.8430421948432922 valid MAE: 0.6868589945922822\n","epoch  85\n","Epoch 85 train loss: tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.13454591453744197\n","Epoch 85 valid loss: 0.8331095576286316 valid MAE: 0.688021006378549\n","epoch  86\n","Epoch 86 train loss: tensor(0.0347, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.14012886100857214\n","Epoch 86 valid loss: 0.8524718880653381 valid MAE: 0.6957959369933178\n","epoch  87\n","Epoch 87 train loss: tensor(0.0280, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1254668025513484\n","Epoch 87 valid loss: 0.8496466875076294 valid MAE: 0.6923464350442219\n","epoch  88\n","Epoch 88 train loss: tensor(0.0219, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.11162605270115808\n","Epoch 88 valid loss: 0.8456496596336365 valid MAE: 0.6924795597879373\n","epoch  89\n","Epoch 89 train loss: tensor(0.0208, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.1091981072252507\n","Epoch 89 valid loss: 0.8365084528923035 valid MAE: 0.685564943680459\n","epoch  90\n","Epoch 90 train loss: tensor(0.0212, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.11064699461647558\n","Epoch 90 valid loss: 0.8570554256439209 valid MAE: 0.697077804878394\n","epoch  91\n","Epoch 91 train loss: tensor(0.0296, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.12951102165137113\n","Epoch 91 valid loss: 0.8461792469024658 valid MAE: 0.6908655444737135\n","epoch  92\n","Epoch 92 train loss: tensor(0.0374, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.14437961549395933\n","Epoch 92 valid loss: 0.820311427116394 valid MAE: 0.6785298369410301\n","epoch  93\n","Epoch 93 train loss: tensor(0.0286, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.12815778645146564\n","Epoch 93 valid loss: 0.8769807815551758 valid MAE: 0.7000252052667212\n","epoch  94\n","Epoch 94 train loss: tensor(0.0225, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.11274651009698226\n","Epoch 94 valid loss: 0.8559200167655945 valid MAE: 0.6955258960433508\n","epoch  95\n","Epoch 95 train loss: tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.09508050770446992\n","Epoch 95 valid loss: 0.8367534279823303 valid MAE: 0.6878243681858606\n","epoch  96\n","Epoch 96 train loss: tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.13169997019118945\n","Epoch 96 valid loss: 0.8342472314834595 valid MAE: 0.6909691469196715\n","epoch  97\n","Epoch 97 train loss: tensor(0.0319, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.13223930203292578\n","Epoch 97 valid loss: 0.8551583290100098 valid MAE: 0.6914674007359228\n","epoch  98\n","Epoch 98 train loss: tensor(0.0194, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.10534229129598649\n","Epoch 98 valid loss: 0.809498131275177 valid MAE: 0.674930066328721\n","epoch  99\n","Epoch 99 train loss: tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>) train MAE: 0.0943035854311254\n","Epoch 99 valid loss: 0.8349181413650513 valid MAE: 0.6897171933927467\n","Testing:\n","mse: 0.7428076267242432\n","Inference Time: 2.077258348464966\n","Inference Params: 1680897\n"]}]},{"cell_type":"markdown","source":["And with that, you've taken your first step into using MultiBench! We hope you find the library useful, and feel free to make an issue on GitHub should there be any confusions regarding how to use an aspect of the package."],"metadata":{"id":"wPVLMGGtM99W"}},{"cell_type":"code","source":["!pip install memory_profiler"],"metadata":{"id":"mgx9AHpZNP_c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701898270215,"user_tz":300,"elapsed":6816,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}},"outputId":"cd56226e-298a-4f82-d311-e090c0abd32f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting memory_profiler\n","  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory_profiler) (5.9.5)\n","Installing collected packages: memory_profiler\n","Successfully installed memory_profiler-0.61.0\n"]}]},{"cell_type":"code","source":["!pip install -U scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"id":"MF8rsFOuEVl-","executionInfo":{"status":"ok","timestamp":1701898718317,"user_tz":300,"elapsed":8966,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}},"outputId":"b768d657-ec85-484d-eb1e-044cf3a1c937"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","Successfully installed scikit-learn-1.3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["sklearn"]}}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"zHNdnWU0UGvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1XW7QdBUG-U","executionInfo":{"status":"ok","timestamp":1701902863821,"user_tz":300,"elapsed":22032,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}},"outputId":"48b61f93-493a-4a09-a7f3-c7248eef2d82"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!mv /content/MultiBench/mosei_ef_r0.pt /content/drive/MyDrive"],"metadata":{"id":"_eKwmyF4UiCG","executionInfo":{"status":"ok","timestamp":1701903018870,"user_tz":300,"elapsed":177,"user":{"displayName":"Marian Qian","userId":"03968435727905727922"}}},"execution_count":8,"outputs":[]}]}